#!/bin/bash
#SBATCH -N 1
#SBATCH -A pnlp
#SBATCH --job-name=train-history-tom
#SBATCH --ntasks-per-node=1
#SBATCH --output=logs/output_train_history_tom_%j.txt
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:1
#SBATCH -t 96:00:00
#SBATCH --mem 16G
# sends mail when process begins, and
# when it ends. Make sure you difine your email
# address
#SBATCH --mail-type=begin
#SBATCH --mail-type=end
#SBATCH --mail-user=t.jingxiaochen@gmail.com

export PATH="/n/fs/pnlp/runzhey/miniconda3/bin:$PATH"
export LANGUAGE=en_US.UTF-8
export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8
which python
source activate tom_new
#source /n/fs/pnlp/runzhey/miniconda3/etc/profile.d/conda.sh
#conda activate tom_new
which python
cd /n/fs/pnlp/runzhey/cocoa/craigslistbargain

# tom_itentity_test
PYTHONPATH=. python multi_rl.py --schema-path data/craigslist-schema.json \
--scenarios-path data/train-scenarios.json \
--valid-scenarios-path data/dev-scenarios.json \
--price-tracker data/price_tracker.pkl \
--agent-checkpoints checkpoint/language/model_best.pt checkpoint/language/model_best.pt \
--model-path checkpoint/history_tom --mappings mappings/language \
--optim adam --rnn-type RNN --rnn-size 300 --max-grad-norm -1 \
--agents pt-neural pt-neural-r \
--report-every 50 --max-turns 20 --num-dialogues 2560 \
--sample --temperature 0.5 --max-length 20 --reward margin \
--dia-num 20 --state-length 4 --epochs 2000 --use-utterance \
--model lf2lf --model-type a2c --tom-test --load-sample cache/hard_pmask/data.pkl \
--learning-rate 0.001 --name history_tom --tom-hidden-size 128 --hidden-depth 1 --tom-model history --gpu 0
